\chapter{Introduction}\label{ch:introduction}

In the digital age written text has become ubiquitous.
Websites, newspapers, online messages and social media all heavily rely on text.
Both the importance and frequency of text-based content has increased in recent years~\autocite{salar-mohtaj-babak-naderi-2022-overview}.
Today the ability to comprehend text is a necessary prerequisite to actively participate in society. % nowadays
This poses a challenge to people with communication impairments~\autocite{easyLanguageBook}.
In Germany, about 12\% of the population has difficulties to understand and write standard German because of reduced literacy~\autocite{schomacker2023data}.
Complicated texts can act as a barrier that prevents these people from taking part in everyday life~\autocite{easyLanguageBook}.
% could lead to exclusion,

Several attempts have been made to create a type of written language that is more comprehensible and accessible.
The primary goal of such languages is to improve communication for a broad range of people with limited reading and writing skills.
This group includes people with communication impairments, people with dementia, language learners, \gls{illit} and older people with visual impairments.

In German, two simplified languages are actively used: \enquote{Easy Language} and \enquote{Plain Language}~\autocite{easyLanguageBook}. % TODO: Deutsch

%The simplified language has to be simple enough to be understood by everyone.
%At the same time it should not be impractical for people that are proficient in standard language.

\section{Easy Language}\label{sec:el}

\gls{el} is a type of simplified language that is regulated by a set of rules.
There are multiple guidelines published by different organizations that define those rules.
The most commonly used guideline is distributed by the \enquote{\gls{nls}}~\autocite{netzwerkLS, easyLanguageBook}.

The \gls{nls} was founded in 2006 and became an official association in 2013~\autocite{netzwerkHistory}.
The association aims to popularize and standardize \gls{el} in Germany.
All members are volunteers~\autocite{netzwerkGoals}.
Among others, the \gls{nls} includes the following people in their target group:
\begin{itemize}[noitemsep]
    \item people with learning difficulties
    \item people with the illness dementia
    \item people that are not proficient in German
    \item people with reduced reading abilities
\end{itemize}
The \gls{nls} intends that texts written in \gls{el} are verified by certified examiners.
Examiners are trained at the \gls{nls} and are usually people in the target group~\autocite{netzwerkPruef}.

\subsection{Rules and Recommendations}\label{subsec:el-rules}
The rules for \gls{el} fall into the categories \enquote{Words}, \enquote{Numbers and Symbols}, \enquote{Sentences}, \enquote{Content} and \enquote{Presentation and Images}.

\subsubsection{Rules for Words}
Words need to be simple.
Technical and foreign words should be avoided.
If difficult words are unavoidable, they have to be explained.
Once a word was introduced to describe a subject, that word should be used again when the subject is referred to (see example in ~\autoref{fig:subject_ref}).

Shorter words are preferred over longer words.
If long words are necessary, they should be split with a hyphen character (e.g.\ \enquote{Bundes-Gleichstellungs-Gesetz} instead of \enquote{Bundesgleichstellungsgesetz}).
Additional rules for words are
\begin{itemize}[noitemsep]
    \item the avoidance of acronyms
    \item the use of active voice over passive voice
    \item avoidance of genitive and conjunctive
    \item reduced use of negation
\end{itemize}
\begin{figure}[htb]
    \begin{center}
        \colorbox{axablue!20}{
            \begin{minipage}{0.5\textwidth}
                \fontfamily{pag}
                A car drove past me.\\
                It was very fast.\\
                The vehicle was red.
            \end{minipage}
        }
        \colorbox{goodgreen!20}{
            \begin{minipage}{0.5\textwidth}
                \fontfamily{pag}
                A car drove past me.\\
                It was very fast.\\
                The car was red.
            \end{minipage}
        }
    \end{center}
    \caption[Text example for the use of the same word to refer to the same subject.]{Synonyms can be confusing (top). Using the same word to refer to the same subject (bottom) is recommended.}
    \label{fig:subject_ref}
\end{figure}

\subsubsection{Rules for Numbers and Symbols}
Numbers and symbols are another aspect addressed by the \gls{nls}-guideline.
Numbers should be written in arabic numerals.
For many people, digits are easier to read than the spelled out word (e.g.\ \enquote{5 horses} instead of \enquote{five horses}).
Thus, smaller numbers are to be written in digits.
Very large numbers are replaced by rough estimations (e.g.\ \enquote{Many People} instead of \enquote{14.795 People}).
The same goes for percentages.
If unusual symbols (e.g.\ §) are used, they need to be explained.

\subsubsection{Rules for Sentences}
The structure of sentences has a big impact on readability. % TODO: quelle?
In \gls{el} sentences are supposed to be short.
Every sentence should only include one statement.
After each sentence, a new line is started.
Sentences with simple structures like \enquote{subject, verb, object} are preferred.
More complex sentences should be broken up in smaller pieces.
These smaller pieces do not necessarily need to form a complete sentence (see example in~\autoref{fig:split_sentence}).
Sentences with subordinate clauses can be broken up similarly.
\begin{figure}
    \begin{center}
        \colorbox{axablue!20}{
            \begin{minipage}{0.6\textwidth}
                Do you want to go swimming or watch a movie?
            \end{minipage}
        }
        \colorbox{goodgreen!20}{
            \begin{minipage}{0.6\textwidth}
                Do you want to go swimming? \\
                Or watch a movie?
            \end{minipage}
        }
    \end{center}
    \caption[Splitting longer sentences into smaller parts in \glsentrylong{el}.]{To comply with the rules of \gls{el} the (top) sentence is split in two. The second part of the (bottom) example does not form a complete sentence on its own.}
    \label{fig:split_sentence}
\end{figure}

\subsubsection{Rules for Content}
Topics should not be distributed across the text.
Related content should be kept together.
References to other texts are to be avoided.
In the translation process from standard German to \gls{el} content can be omitted if necessary.
Likewise, additional content can be added to make the text more understandable.

\subsubsection{Rules for Presentation and Images}
The presentation of text is another aspect that impacts clarity and readability.
The \gls{el}-guideline recommends using a big font size and big line spacing.
Furthermore, text is to be left-aligned.
Backgrounds are supposed to be in light color while the written text is colored darkly.
Text should be structured in many paragraphs with frequent headlines.
Using bullet points instead of comma separated enumerations improves clarity.
Images can be added to accompany the text~\autocite{netzwerkLS}.

\subsection{Prevalence and Adoption of Easy Language}\label{subsec:el-adop}

\glsentrylong{el} contains features that go against standard german.
The unique layout with very short lines makes it easy to recognize texts in \gls{el}.
This helps the target group to find texts written in \gls{el} easily.
But the strong divergence from standard German has been repeatedly criticised.
In 2015, the Federal State Parliament of Schleswig-Holstein passed a law to make elections more accessible.
Information regarding elections was sent out to all voters in \gls{el}.
This sparked outrage in the population and was denounced by multiple politicians.
As a result the passed law was reverted~\autocite{easyLanguageBook}.

While \gls{el} has yet to find acceptance in the general population, it has again been incorporated into German law.
In 2002 the \gls{bgg} was adopted.
The \gls{bgg} guarantees equal living conditions to all people regardless of disabilities.
In 2018 the \gls{bgg} was extended to include clearer instructions for accessibility~\autocite{bggInfo}.
Since then, public authorities have to provide information in \gls{el} as specified in section 2, paragraph 11~\autocite{bgg2018}.
Today \gls{el} can be found on many websites of government departments and municipal institutions (e.g.\ the City of Cologne: \url{https://www.stadt-koeln.de/artikel/07808/index.html}).

\begin{figure}
    \centering
    \colorbox{goodgreen!20}{
        \begin{minipage}{0.6\textwidth}
            Fische sind Tiere. \\
            Sie leben im Wasser. \\
            In Flüssen, im Meer und in Seen. \\
            \\
            Fische atmen durch Kiemen. \\
            Das ist ein Körper-teil. \\
            Dadurch können sie unter Wasser atmen.
        \end{minipage}
    }
    \caption[Example text written in \glsentrylong{el}.]{Example text written in \gls{el} taken from the online dictionary \enquote{Hurraki}\footnotemark.
    The short sentences and frequent line breaks create a very distinct look.}
    \label{fig:easy_text}
\end{figure}


\section{Plain Language}\label{sec:pl}
\gls{pl} is a simplified language that is much closer to standard language.
Originally, it was not intended for people with disabilities.
\gls{pl} is often used to explain domain-specific texts in expert language to less informed people.
Moreover, it addresses language learners, e.g.\ migrants and people that learn a second language~\autocite{easyLanguageBook}.

\gls{pl} is a more international concept that can be found in many different languages.
It is listed as a form of communication in the \gls{un} and is referred to in Article 9 under the aspect of accessibility~\autocite{un2008}.
In the English language guidelines for \gls{pl} have existed for a long time.
Some early works on more accessible language were published in the beginning of the 20th century.
%From the 1960s on the US government pushed to propagate the use of \gls{pl}.
%The goal was to improve communication between citizens and experts from administrative institutions.
%Several instruction manuals for \gls{pl} were distributed.
%Since 2010 federal agencies in the US are required to offer information in a form that is well understood by the citizens.
\footnotetext{\url{https://hurraki.de/wiki/Fische}}

In Germany efforts for \gls{pl} have only been made very recently.
In the 1980s \enquote{Bürgernahe Sprache} (in English: \enquote{language that is close to the citizens}) was created to make administrative texts more comprehensible.
However, \enquote{Bürgernahe Sprache} does not take people with communication impairments and less educated people into account.
%Thus, it does not satisfy all expected conditions of a simplified language.
In the 2000s multiple approaches for \gls{pl} with a broader target groups were attempted.
But none of them have been widely accepted as a standard yet.
Typical features of \gls{pl} are
\begin{itemize}[noitemsep]
    \item usage of common words
    \item usage of short words
    \item avoidance of ambiguous words
    \item precise formulations
    \item short sentences
    \item active voice
    \item clear sentence structure (e.g.\ a maximum of two subordinate clauses)
    \item avoidance of acronyms
\end{itemize}
These directives are similar to some rules in the \gls{el}-guideline.
Contrary to \gls{el}, \gls{pl} does not break any rules of standard German.
That might be a reason why \gls{pl} is generally viewed in a more positive light than \gls{el} by many people. % viewed favorably
Moreover, \gls{pl} can be more flexible and less restrictive as there are no fixed rules.
Writers of \gls{pl} are supposed to factor in the audience of the text and make changes accordingly~\autocite{easyLanguageBook}.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/easy_languages}
    \caption[Different levels of text complexity and comprehensibility.]{Different levels of text complexity and comprehensibility. The different types of languages overlap in certain aspects~\autocite{easyLanguageBook}}
    \label{fig:languages}
\end{figure}

\section{Terminologie}\label{sec:term}
The naming for \glsfirst{el} and \glsfirst{pl} can sometimes cause confusion as the German \enquote{leicht} and \enquote{einfach} can both be translated as \enquote{easy}.
Moreover, \glsentrylong{el} is sometimes referred to as \enquote{Easy-to-read Language} which itself is an established concept in the English-speaking world.
But \textcite{easyLanguageBook} argues that the term \enquote{Easy-to-read Language} is too restrictive and advocates for \gls{el} instead.
There are other proposed names like \enquote{simple language} but they are generally less established than \gls{el} and \gls{pl}.

Another measure for text complexity that is often used in the context of language simplification is the \gls{cefr}.
It uses a six-point scale to assess people's language abilities
From beginner to proficient the levels are A1, A2, B1, B2, C1 and C2~\autocite{cefr_camb}.
Labeling a text with a \gls{cefr}-level means that a person on that level has no problems comprehending the text.
\textcite{schomacker2023data} equate \gls{el} with the \gls{cefr}-level A2.
%TODO: rather A1

% TODO:(BITV 2.0)

%    different guidelines:
%        inclusion europe
%        Netzwerk Leichte Sprache -> most commonly used
%        Barrierefreie-Informationstechnik-Verordnung (BITV 2.0)
%    rulebooks published by Duden


\section{Automatic Language Simplification}\label{sec:langSimp}

Writing texts in \gls{pl} or \gls{el} and translating complex texts into simpler forms requires much effort~\autocite{easyLanguageBook}.
Hence, there is a demand for tools that can assist in this process.

In the context of \gls{nlp} the task of computer aided reduction of text complexity is known as \gls{ats}~\autocite{Ansch_tz_2023}.
The goal of \gls{ats} is to create a system that takes a text in standard or expert language as an input and outputs a simplified version of that text.
\gls{ats} is similar to other \gls{nlp}-tasks like summarization~\autocite{rios-etal-2021-new} and language translation~\autocite{aumiller2022klexikon}.
It is a \gls{seq2seq}-task~\autocite{Ansch_tz_2023} meaning the desired system has to processes and output texts of varying lengths.
\gls{ats} is a relatively new \gls{nlp}-task~\autocite{schomacker2023data}.
Especially simplification of German text has not seen a lot of research~\autocite{Ansch_tz_2023}.

\subsection{Related Work}\label{subsec:related-work}

Some \gls{ats}-methods focus only on sentence-level simplifications while other approaches aim to simplify whole documents.
Simplifications on sentence-level have the advantage that the \gls{ats}-System has to perform less complex transformations on the text.
But certain features of \gls{el} like content order and structure (see section~\ref{subsec:el-rules}) cannot be taken into account. %TODO: Braucht das eine quelle oder ist das offensichtlich?
Document-level simplifications do not have this problem.
However, they require the \gls{ats}-system to be able to process longer sequences and to carry out very complex modifications.

An early rule-based approach for language simplification into \gls{el} was presented by~\autocite{suter2016}.
This approach employed dictionaries to substitute difficult symbols.
Sentences and long words were split through a defined rule-set and additional explanations were added by inserting entries from the online dictionary \enquote{Hurraki}.
~\autocite{Garain2019} created another rule-based method using parse-trees to simplify english sentences.

Solutions based on \enquote{Deep Learning} are generally superior to rule-based methods for language translation tasks.
However, they require vast amounts of data~\autocite{otter2019survey}.
The data is usually a collection of texts (known as a \enquote{corpus}) which are related to the task at hand.
In the setting of language translation \enquote{parallel data} is very useful.
A parallel corpus contains pairs of source and target texts that function as an example for the task.
For \gls{ats} a parallel example would consist of a source text in standard language and a corresponding simplification.
Creating a parallel corpus is difficult as source and target text need to be properly aligned.
It is much easier to assemble a monolingual corpus that usually only contains texts in the target language~\autocite{chan2023routledge}.
While these monolingual corpora are less optimal than parallel data they can still be used in various ways to improve machine translation systems~\autocite{lample2018unsupervised, burlot2019using, chan2023routledge}.

Unfortunately, data for german language simplification is scarce~\autocite{Ansch_tz_2023}.
Most recent research has focused on creating corpora for \gls{el} and \gls{pl} to make Deep Learning approaches more feasible.

\textcite{klaper-etal-2013-building} built the first parallel corpus for german text simplification that consists of 256 texts~\autocite{ebeling2022}.
This corpus was later extended by~\textcite{battisti-etal-2020-corpus}.
The texts were extracted from PDF files and websites.
The extended corpus includes 6,217 documents of which the majority are monolingual (i.e.\ simplifications only) and is referred to as the \enquote{Web-Corpus} by~\textcite{ebeling2022}.

\textcite{sauberli-etal-2020-benchmarking} gather parallel data from news items provided by the \gls{apa} that were manually simplified under the guidelines of \gls{capito}.
All in all the \enquote{\gls{apa}-Corpus} contains 2,426 distinct documents~\autocite{ebeling2022}.
The collected data is used to train \gls{ats}-models for sentence-level simplifications using the transformer architecture (see section~\ref{sec:trans}).
This is possibly the first transformer-based approach to german \gls{ats}~\autocite{Ansch_tz_2023}.
The company \gls{capito} also built a parallel corpus of about 1000 documents that is not publicly available~\autocite{ebeling2022}.

All the above-mentioned datasets contain a mix of different simplification levels.
Moreover, due to copyright issues, most of the data is not easily accessible~\autocite{stodden-etal-2023-deplain}.

\textcite{rios-etal-2021-new} create and publish a parallel document-level corpus from articles of the Swiss news magazine \enquote{20 Minuten} containing 17,905 article pairs.
The simplifications are written in \gls{pl} and are strongly summarized.
They train transformer-based language models on the published dataset while also including the \enquote{Capito Corpus} and the \enquote{\gls{apa} Corpus}.

Another transformer-based approach for \gls{ats} is presented by~\textcite{spring-etal-2021-exploring}.
Their models are also trained on the corpora \enquote{Capito} and \enquote{\gls{apa}} and can output different levels of simplified language based on the \gls{cefr}.

\textcite{aumiller2022klexikon} align entries from the German children’s encyclopedia \enquote{Klexikon} with Wikipedia articles in standard language.
This method explores the task of simultaneous simplification and summarization, as the Klexikon articles are usually much shorter than their Wikipedia counterparts.

Current publicly available \gls{llm} are capable of completing numerous different tasks.
\textcite{deilen2023using} test the feasibility of using ChatGPT-3.5 as an \gls{ats}-system.
They try different prompt strategies to translate text into \gls{el}.
But while outputs are easier to understand, they are missing information and do not follow the rules of \gls{el}.

\textcite{toborek2023new} experiment with automatic sentence alignment of parallel documents.
They publish corpus of 708 aligned documents by providing \gls{webscraper}s for different websites.

To overcome the aforementioned scarcity of parallel data~\textcite{Ansch_tz_2023} use monolingual \gls{el}-data to pretrain \gls{causal-lm}s.
The pretrained models output text in the style of \gls{el} and show improved capabilities in the \gls{ats}-downstream-task.
They publish the \gls{webscraper}s that were used to gather the monolingual data\footnote{\url{https://github.com/brjezierski/scrapers}}.
Running those scrapers yields more than 20,000 documents in either \gls{el} or \gls{pl}.
%training ATS task on pretrained mBart model (replacing decoder with above-mentioned GPT-like Decoders, trainig cross-attention only)

\textcite{stodden-etal-2023-deplain} address issues with current datasets for german \gls{ats} and provide a new parallel corpus that is more accessible than previous corpora.
It is called \enquote{DEPlain} and contains about 1,000 parallel documents (either in \gls{el} or \gls{pl}) of which parts can be downloaded directly from the internet\footnote{\url{https://github.com/rstodden/DEPlain}}, scraped with a provided script\footnote{\url{https://github.com/rstodden/data_collection_german_simplification}} or be directly requested from the authors.
The corpus contains documents from the \gls{apa} so it might overlap with the \gls{apa} Corpus.

Another small dataset is provided by \textcite{naderi2019subjective}.
It consists of 250 parallel sentence-level simplifications in \gls{pl} and was originally used in the context of text complexity assessment.

%\enquote{Deep Learning} is a subset of \enquote{Machine Learning}~\autocite{jagdaleDeepLearning2022}.
% TODO: diese paper \autocite{jablotschkin-etal-2024-de}

\subsection{Previous Work}\label{subsec:previous-work}

In a previous work~\textcite{klöser2024german} extend the scrapers of~\textcite{Ansch_tz_2023} to gather monolingual texts in \gls{el} and \gls{pl}.
By prompting ChatGPT to generate corresponding texts in standard language, semi-synthetic text pairs are formed.
To encourage variation in the generated text, 15 distinct prompts are used.
The newly formed parallel corpus is then used to train language models on the task of document-level \gls{ats}.
This process is sometimes referred to as \enquote{back-translation}~\autocite{sennrich-etal-2016-improving}.

The trained models are evaluated by applying three different metrics that compare reference simplifications to model outputs.
A closer inspection of these metrics shows that rule-based evaluations for \gls{el} are limited and further research on this topic is needed.
%Manual evaluation reveals that the simplifications

While the results of the trained models are promising, there is still a lot of room for improvement.
\begin{itemize}[noitemsep]
    \item The models have difficulties simplifying short texts (i.e.\ simplifications on sentence-level).
    \item Topics and domains of the training documents were mainly news items, dictionarys or informative texts.
    \gls{generalization} to other domains (e.g.\ fiction or law) is subpar.
    \item There is a certain bias towards texts generated by ChatGPT.
    Simplifications of naturally written texts work well, but are quite different from simplified ChatGPT texts.
    \item Simplifications are very linear in the way that they often align with the content order of their original documents.
    Reorganization of content as encouraged by \gls{el} is rare.
    \item Some model outputs can contain very obvious mistakes that result in nonsensical sentences.
    This possibly results from the limited capabilities of the used base model and architecture.
\end{itemize}
The goal of this work is to improve the aforementioned models by extending the training data and testing different model architectures and training methods.

% TODO: problembeschreibung genauer!

% TODO: Evaluation
% TODO: Testgruppe für Bewertung

% felix@doeppers.com


%From~\autocite{madina2023easytoread} TODO: Survey
%From~\autocite{salar-mohtaj-babak-naderi-2022-overview}: TextComplexity 2022
%
%BLEU: ~\autocite{papineni-etal-2002-bleu}
%SARI: ~\autocite{xu-etal-2016-optimizing}
%METEOR: ~\autocite{banerjee-lavie-2005-meteor}
